<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Fine-Grained User Generated Content Video Quality Assessment">
  <meta property="og:title" content="FineVQ: Fine-Grained User Generated Content Video Quality Assessment"/>
  <meta property="og:description" content="FineVQ: Fine-Grained User Generated Content Video Quality Assessment"/>
  <meta property="og:url" content="https://github.com/DuanHuiyu/FineVQ-project-page"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="FineVQ: Fine-Grained User Generated Content Video Quality Assessment">
  <meta name="twitter:description" content="MoRF avatars are created from short monocular videos and can be rendered in real-time (30+ FPS, 640x640px) on mobile devices">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>FineVQ: Fine-Grained User Generated Content Video Quality Assessment</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title"><a style="color:black;">FineVQ</a>: <a style="color:black;">Fine-Grained User Generated Content Video Quality Assessment</a> </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">Huiyu Duan<sup>1</sup>,</span>
              <span class="author-block">Qiang Hu<sup>1</sup>,</span>
              <span class="author-block">Jiarui Wang<sup>1</sup>,</span>
              <span class="author-block">Liu Yang<sup>1</sup>,</span>
              <span class="author-block">Zitong Xu<sup>1</sup>,</span>
              <span class="author-block">Lu Liu<sup>1</sup>,</span>
              <span class="author-block">Xiongkuo Min<sup>1</sup>,</span>
              <span class="author-block">Chunlei Cai<sup>2</sup>,</span>
              <span class="author-block">Tianxiao Ye<sup>2</sup>,</span>
              <span class="author-block">Xiaoyun Zhang<sup>1</sup>,</span>
              <span class="author-block">Guangtao Zhai<sup>1</sup></span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University,</span>
              <span class="author-block"><sup>2</sup>Bilibili Inc.</span>
            </div>

                  <!-- ArXiv Link -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2412.19238" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2412.19238" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/IntMeGroup/FineVQ" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>

                  <br>

                
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
    <center>
      <img src="static/images/overview.png" alt="Method"/>
      <h2 class="subtitle has-text-centered">
        We present the fine-grained video quality assessment database and model, termed FineVD and FineVQ, respectively
      </h2>
    </center>
    </div>
  </div>
</section>

<!-- <video poster="" id="steve" autoplay controls muted loop playsinline height="100%"> -->

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-chair-t">
        <center>
          <video poster="" id="chair-t" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_1.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-chair-tp">
        <center>
          <video poster="" id="chair-tp" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_0.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-shiba">
        <center>
          <video poster="" id="shiba" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_2.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-fullbody">
        <center>
          <video poster="" id="fullbody" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_9.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-blueshirt">
        <center>
          <video poster="" id="blueshirt" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_16.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-mask">
        <center>
          <video poster="" id="mask" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_11.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-coffee">
        <center>
          <video poster="" id="coffee" controls muted loop playsinline width="80%" height="80%">
            <source src="./static/videos/output_3.mp4"
                    type="video/mp4">
          </video>
        </center>
        </div>
        <div class="item item-coffee">
          <center>
            <video poster="" id="coffee" controls muted loop playsinline width="80%" height="80%">
              <source src="./static/videos/output_13.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
        <div class="item item-coffee">
          <center>
            <video poster="" id="coffee" controls muted loop playsinline width="80%" height="80%">
              <source src="./static/videos/output_4.mp4"
                      type="video/mp4">
            </video>
          </center>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="hero teaser">
  <div class="hero-body has-text-justified">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="container">
          The rapid growth of user-generated content (UGC) videos has produced an urgent need for effective video quality assessment (VQA) algorithms to monitor video quality and guide optimization and recommendation procedures. However, current VQA models generally only give an overall rating for a UGC video, which lacks fine-grained labels for serving video processing and recommendation applications. 
          <br>
          <br>
        </div>
        <div class="container">
          To address the challenges and promote the development of UGC videos, we establish the first large-scale Fine-grained Video quality assessment Database, termed FineVD, which comprises 6104 UGC videos with fine-grained quality scores and descriptions across multiple dimensions. Based on this database, we propose a Fine-grained Video Quality assessment (FineVQ) model to learn the fine-grained quality of UGC videos, with the capabilities of quality rating, quality scoring, and quality attribution. Extensive experimental results demonstrate that our proposed FineVQ can produce fine-grained video-quality results and achieve state-of-the-art performance on FineVD and other commonly used UGC-VQA datasets.
          <br>
          <br>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="hero-body has-text-justified">
    <div class="container is-max-desktop">
      <div class="hero-body">


        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">FineVD</h2>
        <div class="container">
          An overview of the content and construction process of FineVD. (a) Example videos from our database, which contains both common UGC videos and short-form UGC videos. (b) The illustration of subjective data annotation methods, including both quality scoring and quality attribute labeling processes. (c) The quality-related question-answering pairs generated by GPT-4 and revised by human annotators.
          <br>
          <br>
        </div>
        <img src="static/images/dataset.png" alt="Method"/>
        <br>
        <br>
        <br>

        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">FineVQ</h2>
        <div class="container">
          An overview of our proposed FineVQ model. Our model consists of three feature encoders, including an image feature extractor for extracting spatial features from sparse video frames, a motion feature extractor for extracting motion features from the entire video, and a text encoder for extracting aligned text features from prompts. The extracted features are then aligned through projectors and fed into a pre-trained LLM to generate the output results. LoRA weights are introduced to the pre-trained image encoder and the large language model to adapt the models to the quality assessment task.
          <br>
          <br>
        </div>
        <img src="static/images/method.png" alt="Method"/>
        <br>
        <br>
        <br>

        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Performance on FiveVQ</h2>
        <div class="container">
          Performance of state-of-the-art models and the proposed FineVQ on our established FineVD database in terms of the quality scoring task.
          <br>
          <br>
        </div>
        <img src="static/images/results1.png" alt="Method"/>
        <br>
        <br>
        <br>

        <br>
        <br>
        <br>
        <h2 class="title has-text-centered">Performance on Other VQA databases</h2>
        <div class="container">
          Performance comparison between state-of-the-art VQA methods and the proposed FineVQ on six UGC VQA databases
          <br>
          <br>
        </div>
        <img src="static/images/results2.png" alt="Method"/>
        <br>
        <br>
        <br>


        
      </div>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <
    </div>
  </div>
</section> -->


<!-- <section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          
          <p>
            Lorem ipsum dolor sit amet, consectetur adipiscing elit. Proin ullamcorper tellus sed ante aliquam tempus. Etiam porttitor urna feugiat nibh elementum, et tempor dolor mattis. Donec accumsan enim augue, a vulputate nisi sodales sit amet. Proin bibendum ex eget mauris cursus euismod nec et nibh. Maecenas ac gravida ante, nec cursus dui. Vivamus purus nibh, placerat ac purus eget, sagittis vestibulum metus. Sed vestibulum bibendum lectus gravida commodo. Pellentesque auctor leo vitae sagittis suscipit.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!-- <br>
<br>
<br>
<br>
<h2 class="title has-text-centered">Qualitative Novel View Results</h2>

<div class="container">
  Our method also has the capability to produce realistic novel views of multiple objects. Using the Rotation + SAM + Inpaint parts of our method, we show qualitative results of our methods ability to generate novel views given an RGB-D image.
  <br>
  <br>
</div>
<img src="static/images/Inpainted_Qualitative.png" alt="Method"/>


<br>
<br>
<br>
<br> -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{duan2025finevq,
      title={FineVQ: Fine-Grained User Generated Content Video Quality Assessment},
      author={Duan Huiyu, Hu Qiang, Wang Jiarui, Yang Liu, Xu Zitong, Liu Lu, Min Xiongkuo, Cai Chunlei, Ye Tianxiao, Zhang Xiaoyun, Zhai Guangtao},
      booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2025}
}
</code></pre>
    </div>
</section>
<!--End BibTex citation -->






  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://licensebuttons.net/l/by-nc/3.0/88x31.png"/>
            </a><br />This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0">Creative Commons Attribution-NonCommercial 4.0 International License</a> (CC-BY-NC).
          </p>
          <p>
            This webpage is built with the template from <a
                  href="https://github.com/nerfies/nerfies.github.io" target="_blank">NeRFies</a>. We sincerely thank <a href="https://keunhong.com/" target="_blank">Keunhong Park</a> for developing and open-sourcing this template.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
